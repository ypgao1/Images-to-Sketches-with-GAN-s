{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from math import log10\n",
    "import json\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from statistics import mean\n",
    "  \n",
    "\n",
    "from torch.nn import init\n",
    "import functools\n",
    "import itertools\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import time\n",
    "from generators.generators import create_gen\n",
    "from discriminators.discriminators import create_disc\n",
    "from losses.Loss import GANLoss\n",
    "from datasets.datasets import get_dataset\n",
    "from util import ImagePool, set_requires_grad,tensor_to_plt,init_weights, mkdir\n",
    "from Tensorboard_Logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer,opt):\n",
    "    def lambda_rule(epoch):\n",
    "        lr_l = 1.0 - max(0, epoch + 1 + opt.epoch_count - opt.iter_constant) / float(opt.iter_decay + 1)\n",
    "        return lr_l\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "    \n",
    "    return scheduler\n",
    "\n",
    "class Args():\n",
    "    '''\n",
    "    See Pix2Pix.ipynb for hyperparmeter details\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.batch_size = 32\n",
    "        self.test_batch_size = 32\n",
    "        self.input_dim = 3\n",
    "        self.output_dim = 1\n",
    "        self.gen_filters =64\n",
    "        self.disc_filters =64\n",
    "        self.total_iters=6\n",
    "        self.epoch_count =1\n",
    "        self.iter_constant = 200\n",
    "        self.iter_decay = 200\n",
    "        self.lr = 0.0002\n",
    "        self.beta1 = 0.5\n",
    "        self.cuda = True\n",
    "        self.threads = 8\n",
    "        self.seed = 123\n",
    "        self.lamb = 100\n",
    "        self.use_ls = True\n",
    "        self.resblocks = 9\n",
    "        self.norm = \"instance\"\n",
    "        self.dropout = False\n",
    "        self.gen = \"Resnet\"\n",
    "        self.disc= \"Global\"\n",
    "        self.paired_dataset = False\n",
    "        self.dataset_name = \"sketchy\" \n",
    "        self.folder_name = \"12345\"\n",
    "    \n",
    "        self.lambda_recon =10 #reconstruction loss weight\n",
    "        self.pool_size=50 #how many images we store in our image pool, that keeps track of past images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Train_CycleGan:\n",
    "    def __init__(self,opt,traindataset,testdataset):\n",
    "        \n",
    "        self.dataset = DataLoader(dataset=traindataset, batch_size=opt.batch_size, shuffle=True,num_workers=opt.threads)\n",
    "        self.test_set = DataLoader(dataset=testdataset, batch_size=opt.test_batch_size, shuffle=True,num_workers=opt.threads)\n",
    "        self.atest, self.btest,self.btestreal = next(iter(self.test_set))\n",
    "        self.dataviz = DataLoader(dataset=traindataset, batch_size=opt.test_batch_size, shuffle=True,num_workers=opt.threads)\n",
    "        self.atrain, self.btrain,self.btrainreal = next(iter(self.dataviz))\n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if opt.cuda else \"cpu\")\n",
    "        self.writer = Logger(opt.folder_name)\n",
    "        self.writer.write_photo_to_tb(self.atest,\"photos test\")\n",
    "        self.writer.write_sketch_to_tb(self.btestreal,\"sketches test\")\n",
    "        self.writer.write_photo_to_tb(self.atrain,\"photos train\")\n",
    "        self.writer.write_sketch_to_tb(self.btrain,\"sketches train\")\n",
    "\n",
    "        self.G_ab = create_gen(opt.gen,opt.input_dim,opt.output_dim,opt.gen_filters,opt.norm)\n",
    "        self.G_ab.to(self.device)\n",
    "        init_weights(self.G_ab)\n",
    "        \n",
    "        self.G_ba = create_gen(opt.gen,opt.output_dim,opt.input_dim,opt.gen_filters,opt.norm)\n",
    "        self.G_ba.to(self.device)\n",
    "        init_weights(self.G_ba)\n",
    "        \n",
    "\n",
    "        self.D_b = create_disc(opt.disc,opt.output_dim,use_sigmoid=False) #discriminator for sketches\n",
    "        self.D_b.to(self.device)\n",
    "        init_weights(self.D_b)\n",
    "        \n",
    "        self.D_a = create_disc(opt.disc,opt.input_dim,use_sigmoid=False) #discriminator for images\n",
    "        self.D_a.to(self.device)\n",
    "        init_weights(self.D_a)\n",
    "\n",
    "\n",
    "        self.MSE = nn.MSELoss().to(self.device)\n",
    "        self.L1 = nn.L1Loss().to(self.device)\n",
    "\n",
    "        self.schedulers = []\n",
    "        self.optimizers = []\n",
    "        \n",
    "        self.optimizer_G = torch.optim.Adam(itertools.chain(self.G_ab.parameters(), \n",
    "                                                            self.G_ba.parameters()),\n",
    "                                            lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "        self.optimizer_D = torch.optim.Adam(itertools.chain(self.D_a.parameters(),\n",
    "                                                            self.D_b.parameters()),\n",
    "                                            lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "            \n",
    "        \n",
    "        self.optimizers.append(self.optimizer_G)\n",
    "        self.optimizers.append(self.optimizer_D)\n",
    "\n",
    "        for optimizer in self.optimizers:\n",
    "            self.schedulers.append(get_scheduler(optimizer,opt))\n",
    "        \n",
    "    \n",
    "        self.gen_loss = []\n",
    "        self.disc_loss = []\n",
    "        self.l1_loss = []\n",
    "        self.gan_loss = []\n",
    "        \n",
    "        self.fake_A_pool = ImagePool(opt.pool_size)  # create image buffer to store previously generated images\n",
    "        self.fake_B_pool = ImagePool(opt.pool_size)  # create image buffer to store previously generated images\n",
    "\n",
    "    def train(self,opt):\n",
    "        \n",
    "        #train\n",
    "        for epoch in range(opt.epoch_count, opt.total_iters+1):\n",
    "\n",
    "            #go through each batch\n",
    "            lossdlist = []\n",
    "            lossglist = []\n",
    "            t1 = time.time()\n",
    "                                   \n",
    "            for i, batch in enumerate(self.dataset):\n",
    "                print(\"training epoch \",epoch,\"batch\", i,\"/\",len(self.dataset))\n",
    "                real_A, real_B = batch[0].to(self.device), batch[1].to(self.device)\n",
    "\n",
    "\n",
    "                set_requires_grad(nets=self.D_a, requires_grad=False)\n",
    "                set_requires_grad(nets=self.D_b, requires_grad=False)\n",
    "                self.optimizer_G.zero_grad()\n",
    " \n",
    "                \n",
    "                fake_A = self.G_ba(real_B)\n",
    "                fake_B = self.G_ab(real_A)\n",
    "                recon_A = self.G_ba(fake_B)\n",
    "                recon_B = self.G_ab(fake_A)\n",
    "                \n",
    "                pred_fake_A = self.D_a(fake_A)\n",
    "                pred_fake_B = self.D_b(fake_B)\n",
    "                \n",
    "                real_label = torch.ones(pred_fake_A.size()).to(self.device)\n",
    "                \n",
    "                gen_loss_A = self.MSE(pred_fake_A, real_label)\n",
    "                gen_loss_B = self.MSE(pred_fake_B, real_label)\n",
    "                \n",
    "                cycle_loss_A = self.L1(recon_A, real_A) * opt.lambda_recon\n",
    "                cycle_loss_B = self.L1(recon_B, real_B) * opt.lambda_recon\n",
    "                \n",
    "                gen_loss = gen_loss_A + gen_loss_B + cycle_loss_A + cycle_loss_B \n",
    "                lossglist.append(gen_loss.item())\n",
    "                gen_loss.backward()\n",
    "                self.optimizer_G.step()\n",
    "                ############################################################\n",
    "                set_requires_grad(nets=self.D_a, requires_grad=True)\n",
    "                set_requires_grad(nets=self.D_b, requires_grad=True)\n",
    "                \n",
    "                self.optimizer_D.zero_grad()\n",
    "\n",
    "                fake_A = self.fake_A_pool.query(fake_A) #.to(self.device)\n",
    "                fake_B = self.fake_B_pool.query(fake_B) #.to(self.device)\n",
    "\n",
    "                pred_real_A = self.D_a(real_A)\n",
    "                pred_fake_A = self.D_a(fake_A.detach())\n",
    "                pred_real_B = self.D_b(real_B)\n",
    "                pred_fake_B = self.D_b(fake_B.detach())\n",
    "\n",
    "                real_label = torch.ones(pred_real_A.size()).to(self.device)\n",
    "                fake_label = torch.zeros(pred_fake_A.size()).to(self.device)\n",
    "\n",
    "                a_dis_real_loss = self.MSE(pred_real_A, real_label)\n",
    "                a_dis_fake_loss = self.MSE(pred_fake_A, fake_label)\n",
    "                b_dis_real_loss = self.MSE(pred_real_B, real_label)\n",
    "                b_dis_fake_loss = self.MSE(pred_fake_B, fake_label)\n",
    "\n",
    "                a_dis_loss = (a_dis_real_loss + a_dis_fake_loss)*0.5\n",
    "                b_dis_loss = (b_dis_real_loss + b_dis_fake_loss)*0.5\n",
    "                lossdlist.append(a_dis_loss.item()*.5 + b_dis_loss.item()*0.5)\n",
    "\n",
    "                a_dis_loss.backward()\n",
    "                b_dis_loss.backward()\n",
    "\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "               \n",
    "\n",
    "            #update_learning_rate()\n",
    "            for scheduler in self.schedulers:\n",
    "                scheduler.step()\n",
    "            lr = self.optimizers[0].param_groups[0]['lr']\n",
    "            print('learning rate = %.7f' % lr)\n",
    "            t2 = time.time()\n",
    "            diff = t2-t1\n",
    "            print(\"iteration:\",epoch,\"loss D:\", mean(lossdlist),\"loss G:\", mean(lossglist))\n",
    "            print(\"Took \", diff, \"seconds\")\n",
    "            print(\"Estimated time left:\", diff*(opt.total_iters - epoch))\n",
    "\n",
    "            self.gen_loss.append(mean(lossglist))\n",
    "            self.disc_loss.append(mean(lossdlist))\n",
    "\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                with torch.no_grad():\n",
    "                    out1 = self.G_ab(self.atrain.to(self.device))\n",
    "                    title= \"Epoch \"+str(epoch) +\"Training\"\n",
    "                    self.writer.write_sketch_to_tb(out1.detach(),title) \n",
    "                    \n",
    "                    out2 = self.G_ab(self.atest.to(self.device))\n",
    "                    title= \"Epoch \"+str(epoch)\n",
    "                    self.writer.write_sketch_to_tb(out2.detach(),title)\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.writer.plot_losses(self.gen_loss,self.disc_loss,[])\n",
    "    \n",
    "    def save_model(self,folderpath,modelpath):\n",
    "        mkdir(folderpath)\n",
    "        torch.save({\n",
    "            'genAB': self.G_ab.module.state_dict(),\n",
    "            'genBA': self.G_ba.module.state_dict(),\n",
    "            'discA': self.D_a.module.state_dict(),\n",
    "            'discB': self.D_b.module.state_dict(),\n",
    "            'optimizerG_state_dict': self.optimizer_G.state_dict(),\n",
    "            'optimizerD_state_dict': self.optimizer_D.state_dict(),\n",
    "            \n",
    "            }, modelpath)\n",
    "        \n",
    "    def save_arrays(self,path):\n",
    "        np.save( os.path.join(path,\"ganloss\"),np.asarray(self.gen_loss))\n",
    "        np.save( os.path.join(path,\"discloss\"),np.asarray(self.disc_loss))\n",
    "        np.save( os.path.join(path,\"l1loss\"),np.asarray(self.l1_loss))\n",
    "        \n",
    "    def save_hyper_params(self,folderpath,opt):\n",
    "        with open(os.path.join(folderpath,'params.txt'), 'w') as file:\n",
    "             file.write(json.dumps(opt.__dict__)) \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Args()\n",
    "\n",
    "photo_path_train = os.path.join(os.getcwd(),\"data\",opt.dataset_name,\"train\", \"photo\")\n",
    "sketch_path_train = os.path.join(os.getcwd(),\"data\",opt.dataset_name,\"train\", \"sketch\")\n",
    "train_set = get_dataset(photo_path_train,sketch_path_train, opt,flip=False,jitter=False,erase=True)\n",
    "\n",
    "photo_path_test = os.path.join(os.getcwd(),\"data\",opt.dataset_name,\"test\", \"photo\")\n",
    "sketch_path_test = os.path.join(os.getcwd(),\"data\",opt.dataset_name,\"test\", \"sketch\")\n",
    "testing_set =  get_dataset(photo_path_test,sketch_path_test, opt,flip=False,jitter=False,erase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exps = [opt]\n",
    "for option in exps:\n",
    "    experiment = Train_CycleGan(option,train_set,testing_set)\n",
    "    experiment.train(option)\n",
    "    folderpath = os.path.join(os.getcwd(),option.folder_name)\n",
    "    model_path = os.path.join(os.getcwd(),option.folder_name,option.gen)\n",
    "    experiment.save_model(folderpath,model_path)\n",
    "    experiment.save_arrays(folderpath)\n",
    "    experiment.save_hyper_params(folderpath,opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
